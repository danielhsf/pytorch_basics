{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d898bf5a",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc8043aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07991fd2",
   "metadata": {},
   "source": [
    "## Check if CUDA is avaiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d5b03e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6f0a49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91550a2c",
   "metadata": {},
   "source": [
    "## Downloading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88d039a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "mnist_train = datasets.MNIST(root=\"./datasets\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = datasets.MNIST(root=\"./datasets\", train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05bbee78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of MNIST training examples: 60000\n",
      "Number of MNIST test examples: 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of MNIST training examples: {}\".format(len(mnist_train)))\n",
    "print(\"Number of MNIST test examples: {}\".format(len(mnist_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfb12ec",
   "metadata": {},
   "source": [
    "# Plotting a random sample from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b2e88ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default image shape: torch.Size([1, 28, 28]) \n",
      "\n",
      "Reshaped image shape: torch.Size([28, 28]) \n",
      "\n",
      "The label for this image: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "i = random.randint(0,len(mnist_train))\n",
    "image, label = mnist_train[i]\n",
    "\n",
    "# Plot the image\n",
    "print(\"Default image shape: {} \\n\".format(image.shape))\n",
    "image = image.reshape([28,28])\n",
    "print(\"Reshaped image shape: {} \\n\".format(image.shape))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "\n",
    "# Print the label\n",
    "print(\"The label for this image: {}\".format(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d114dc",
   "metadata": {},
   "source": [
    "### Creating a loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4766d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a567562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the minibatch of images: torch.Size([100, 1, 28, 28])\n",
      "Shape of the minibatch of labels: torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "data_train_iter = iter(train_loader)\n",
    "images, labels = data_train_iter.next()\n",
    "\n",
    "print(\"Shape of the minibatch of images: {}\".format(images.shape))\n",
    "print(\"Shape of the minibatch of labels: {}\".format(labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be43e579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of input x: torch.Size([100, 784])\n"
     ]
    }
   ],
   "source": [
    "x = images.view(-1, 28*28)\n",
    "print(\"The shape of input x: {}\".format(x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c10591f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly initialize weights W\n",
    "W = torch.randn(784, 10)/np.sqrt(784)\n",
    "W.requires_grad_()\n",
    "\n",
    "# Initialize bias b as 0s\n",
    "b = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eeca401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear transformation with W and b\n",
    "y = torch.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ffc72ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2487,  0.5159, -1.0786, -0.5606, -0.5276, -0.0930, -0.2293,  0.3257,\n",
      "        -0.6856, -0.2052], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(y[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "862bb8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "py[0] from equation: tensor([0.0932, 0.2002, 0.0407, 0.0682, 0.0705, 0.1089, 0.0950, 0.1656, 0.0602,\n",
      "        0.0974], grad_fn=<SelectBackward>)\n",
      "py[0] with torch.nn.functional.softmax: tensor([0.0932, 0.2002, 0.0407, 0.0682, 0.0705, 0.1089, 0.0950, 0.1656, 0.0602,\n",
      "        0.0974], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "# py_eq = torch.exp(y) / torch.sum(torch.exp(y), dim=1, keepdim=True)\n",
    "\n",
    "#Softmax to probabilities with torch.nn.functional\n",
    "import torch.nn.functional as F\n",
    "py = F.softmax(y, dim=1)\n",
    "print(\"py[0] with torch.nn.functional.softmax: {}\".format(py[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12e20a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross entropy with torch.nn.functional.cross_entropy: 2.4003756046295166\n"
     ]
    }
   ],
   "source": [
    "#cross_entropy_eq = torch.mean(-torch.log(py_eq)[range(labels.shape[0]),labels])\n",
    "\n",
    "# Cross-entropy loss with torch.nn.functional\n",
    "cross_entropy = F.cross_entropy(y, labels)\n",
    "print(\"cross entropy with torch.nn.functional.cross_entropy: {}\".format(cross_entropy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c93cc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.SGD([W,b], lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "033adc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "179f327e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0183,  0.0809, -0.0477, -0.0233, -0.0541,  0.0141,  0.0184, -0.0115,\n",
       "         0.0211,  0.0202])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b58156d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e25ea446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0018, -0.0081,  0.0048,  0.0023,  0.0054, -0.0014, -0.0018,  0.0012,\n",
       "        -0.0021, -0.0020], requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b67094b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b.grad before zero_grad(): tensor([-0.0183,  0.0809, -0.0477, -0.0233, -0.0541,  0.0141,  0.0184, -0.0115,\n",
      "         0.0211,  0.0202])\n",
      "b.grad after zero_grad(): tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(\"b.grad before zero_grad(): {}\".format(b.grad))\n",
    "optimizer.zero_grad()\n",
    "print(\"b.grad after zero_grad(): {}\".format(b.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8012d3",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "071d6bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286f3d411d0549cb943f5daaa6d695e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Iterate through train set minibatchs \n",
    "for images, labels in tqdm(train_loader):\n",
    "    # Zero out the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    x = images.view(-1, 28*28)\n",
    "    y = torch.matmul(x, W) + b\n",
    "    cross_entropy = F.cross_entropy(y, labels)\n",
    "    # Backward pass\n",
    "    cross_entropy.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a951413",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0c99164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8edc8add07f44606bc28529a39fde83d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.902400016784668\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = len(mnist_test)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Iterate through test set minibatchs \n",
    "    for images, labels in tqdm(test_loader):\n",
    "        # Forward pass\n",
    "        x = images.view(-1, 28*28)\n",
    "        y = torch.matmul(x, W) + b\n",
    "        \n",
    "        predictions = torch.argmax(y, dim=1)\n",
    "        correct += torch.sum((predictions == labels).float())\n",
    "    \n",
    "print('Test accuracy: {}'.format(correct/total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
